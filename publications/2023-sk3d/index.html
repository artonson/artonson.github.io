<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Skoltech3D: Multi-sensor large-scale dataset for multi-view 3D reconstruction | Alexey Artemov</title>
<link rel=stylesheet href=https://artonson.github.io/css/style.css><link rel=stylesheet href=https://artonson.github.io/css/fonts.css></head><body><nav><ul class=menu><li><a href=https://artonson.github.io/>Home</a></li><li><a href=https://artonson.github.io/cv_alexey_artemov.pdf>CV</a></li><li><a href=https://artonson.github.io/publications>Research</a></li><li><a href=https://artonson.github.io/teaching>Education</a></li><li><a href=https://artonson.github.io/art>Art & Heritage</a></li><li><a href=https://artonson.github.io/press>Press</a></li><li class=menu-standard><a href=mailto:artonson@yandex.ru><img src=https://simpleicons.org/icons/maildotru.svg style=max-width:3%;min-width:18px alt=E-Mail></a></li><li class=menu-standard><a href=https://github.com/artonson><img src=https://simpleicons.org/icons/github.svg style=max-width:3%;min-width:18px alt="Github repo"></a></li><li class=menu-standard><a href="https://scholar.google.ru/citations?user=5lVsH-IAAAAJ&hl=en"><img src=https://simpleicons.org/icons/googlescholar.svg style=max-width:3%;min-width:18px alt="Google Scholar"></a></li><li class=menu-standard><a href=https://www.youtube.com/channel/UCO946RPg2Yp2PXFzon9_73g><img src=https://simpleicons.org/icons/youtube.svg style=max-width:3%;min-width:18px alt=Youtube></a></li><li class=menu-standard><a href=https://www.linkedin.com/artonson><img src=https://simpleicons.org/icons/linkedin.svg style=max-width:3%;min-width:18px alt=LinkedIn></a></li><li class=menu-standard><a href=https://twitter.com/artonson><img src=https://simpleicons.org/icons/twitter.svg style=max-width:3%;min-width:18px alt=Twitter></a></li><li class=menu-standard><a href=https://t.me/research_meets_art><img src=https://simpleicons.org/icons/telegram.svg style=max-width:3%;min-width:18px alt="Telegram Channel"></a></li></ul><hr></nav><div class=article-meta><h1>Skoltech3D: Multi-sensor large-scale dataset for multi-view 3D reconstruction</h1></div><div class=single-authors-wrap><table class=single-authors id=single-authors><tr><td>Oleg Voynov</td><td>Gleb Bobrovskikh</td><td>Pavel Karpyshev</td><td>Saveliy Galochkin</td></tr><tr><td>Andrei-Timotei Ardelean</td><td>Arseniy Bozhenko</td><td>Ekaterina Karmanova</td><td>Pavel Kopanev</td></tr><tr><td>Yaroslav Labutin-Rymsho</td><td>Ruslan Rakhimov</td><td>Aleksandr Safin</td><td>Valerii Serpiva</td></tr><tr><td>Alexey Artemov</td><td>Evgeny Burnaev</td><td>Dzmitry Tsetserukou</td><td>Denis Zorin</td></tr><tr></tr></table></div><div class=publication-single-teaser><img src=https://artonson.github.io/publications/2023-sk3d/image-big.jpg width=768/></div><div class=publication-single-venue>CVPR 2023</div><div><h2>Abstract</h2><span class=publications-single-abstract>We present a multi-sensor dataset for multi-view 3D surface reconstruction. It includes registered RGB and depth data from 7 sensors of different resolutions and modalities (a): smartphones, Intel RealSense, Microsoft Kinect, industrial cameras, and structured-light scanner. The scenes are selected to emphasize a diverse set of material properties challenging for existing algorithms (c), such as featureless (F), highly specular with sharp reflections (S), or translucent (T), as illustrated with reconstructions produced by state-of-the-art algorithms (compare with an “easy” object on the bottom right). We provide around 1.4 million images of 107 different scenes acquired from 100 viewing directions under 14 lighting conditions (b). We expect our dataset will be useful for evaluation and training of 3D reconstruction algorithms and for related tasks.</span></div><main></main><div><h2>Video</h2><iframe class=video width=100% height=400 src=https://www.youtube.com/embed/KPwghPyZWDE frameborder=0 allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div><h2>Resources</h2><ul><li>Fulltext PDF: <a href=http://openaccess.thecvf.com/content/CVPR2023/papers/Voynov_Multi-Sensor_Large-Scale_Dataset_for_Multi-View_3D_Reconstruction_CVPR_2023_paper.pdf>Skoltech3D: Multi-sensor large-scale dataset for multi-view 3D reconstruction</a></li><li>Supplementary PDF: <a href=https://openaccess.thecvf.com/content/CVPR2023/supplemental/Voynov_Multi-Sensor_Large-Scale_Dataset_CVPR_2023_supplemental.pdf>Skoltech3D: Multi-sensor large-scale dataset for multi-view 3D reconstruction Supplementary Materials</a></li><li>Source code: <a href=https://github.com/Skoltech-3D/sk3d_data>https://github.com/Skoltech-3D/sk3d_data</a></li><li>Video <a href="https://www.youtube.com/watch?v=KPwghPyZWDE">Video</a></li><li>Official project page: <a href=https://skoltech3d.appliedai.tech>https://skoltech3d.appliedai.tech</a></li><li>Citing:<pre tabindex=0><code>@inproceedings{2023-sk3d,
 author = {Voynov, Oleg and Bobrovskikh, Gleb and Karpyshev, Pavel and Galochkin, Saveliy and Ardelean, Andrei-Timotei and Bozhenko, Arseniy and Karmanova, Ekaterina and Kopanev, Pavel and Labutin-Rymsho, Yaroslav and Rakhimov, Ruslan and others},
 booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
 pages = {21392--21403},
 title = {Multi-sensor large-scale dataset for multi-view 3D reconstruction},
 year = {2023}
}
</code></pre></li></ul></div><footer><hr>© <a href=https://artonson.github.io>Alexey Artemov</a> 2021–2024 | <a href=mailto:artonson@yandex.ru>Email</a> | <a href=https://github.com/artonson>Github</a> | <a href="https://scholar.google.ru/citations?user=5lVsH-IAAAAJ&amp;hl=en">Scholar</a> | <a href=https://www.youtube.com/channel/UCO946RPg2Yp2PXFzon9_73g>YouTube</a> | <a href=https://www.linkedin.com/in/artonson/>LinkedIn</a> | <a href=https://twitter.com/artonson>Twitter</a> | <a href=https://t.me/research_meets_art>Telegram</a></footer></body></html>
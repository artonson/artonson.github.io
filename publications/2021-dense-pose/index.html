<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Making DensePose Fast and Light | Alexey Artemov</title><link rel=stylesheet href=https://artonson.github.io/css/style.css><link rel=stylesheet href=https://artonson.github.io/css/fonts.css></head><body><nav><ul class=menu><li><a href=https://artonson.github.io/>Home</a></li><li><a href=https://artonson.github.io/cv_alexey_artemov.pdf>CV</a></li><li><a href=https://artonson.github.io/publications>Publications</a></li><li><a href=https://artonson.github.io/teaching>Teaching</a></li><li><a href=https://artonson.github.io/students>Students</a></li><li><a href=https://artonson.github.io/code_resources>Code & Resources</a></li><li><a href=https://artonson.github.io/press>Press</a></li><li class=menu-standard><a href=mailto:a.artemov@skoltech.ru><img src=https://simpleicons.org/icons/maildotru.svg style=max-width:3%;min-width:20px alt=E-Mail></a></li><li class=menu-standard><a href=https://github.com/artonson><img src=https://simpleicons.org/icons/github.svg style=max-width:3%;min-width:20px alt="Github repo"></a></li><li class=menu-standard><a href="https://scholar.google.ru/citations?user=5lVsH-IAAAAJ&hl=en"><img src=https://simpleicons.org/icons/googlescholar.svg style=max-width:3%;min-width:20px alt="Google Scholar"></a></li><li class=menu-standard><a href=https://www.youtube.com/channel/UCO946RPg2Yp2PXFzon9_73g><img src=https://simpleicons.org/icons/youtube.svg style=max-width:3%;min-width:20px alt=Youtube></a></li><li class=menu-standard><a href=https://www.linkedin.com/artonson><img src=https://simpleicons.org/icons/linkedin.svg style=max-width:3%;min-width:20px alt=LinkedIn></a></li><li class=menu-standard><a href=https://twitter.com/artonson><img src=https://simpleicons.org/icons/twitter.svg style=max-width:3%;min-width:20px alt=Twitter></a></li></ul><hr></nav><div class=article-meta><h1>Making DensePose Fast and Light</h1></div><div class=single-authors-wrap><table class=single-authors id=single-authors><tr><td>Ruslan Rakhimov</td><td>Emil Bogomolov</td><td>Alexandr Notchenko</td><td>Fung Mao</td><td>Alexey Artemov</td></tr><tr><td>Denis Zorin</td><td>Evgeny Burnaev</td></tr></table></div><div class=publication-single-teaser><img src=https://artonson.github.io/publications/2021-dense-pose/image-big.jpg width=768/></div><div class=publication-single-venue>WACV
2021</div><div><h2>Abstract</h2><span class=publications-single-abstract>DensePose estimation task is a significant step forward for enhancing user experience computer vision applications ranging from augmented reality to cloth fitting. Existing neural network models capable of solving this task are heavily parameterized and a long way from being transferred to an embedded or mobile device. To enable Dense Pose inference on the end device with current models, one needs to support an expensive server-side infrastructure and have a stable internet connection. To make things worse, mobile and embedded devices do not always have a powerful GPU inside. In this work, we target the problem of redesigning the DensePose R-CNN model&rsquo;s architecture so that the final network retains most of its accuracy but becomes more light-weight and fast. To achieve that, we tested and incorporated many deep learning innovations from recent years, specifically performing an ablation study on 23 efficient backbone architectures, multiple two-stage detection pipeline modifications, and custom model quantization methods. As a result, we achieved 17 times model size reduction and 2 times latency improvement compared to the baseline model.</span></div><main></main><div><h2>Resources</h2><ul><li>Fulltext PDF: <a href=https://openaccess.thecvf.com/content/WACV2021/papers/Rakhimov_Making_DensePose_Fast_and_Light_WACV_2021_paper.pdf>Making DensePose Fast and Light</a></li><li>Source code: <a href=https://github.com/zetyquickly/DensePoseFnL>https://github.com/zetyquickly/DensePoseFnL</a></li><li>Slides: <a href="https://www.dropbox.com/s/89jx45uibpqjx8p/2021-dense-pose.key.zip?dl=0">Slides</a></li><li>Citing:<pre tabindex=0><code>@inproceedings{2021-dense-pose,
 author = {Rakhimov, Ruslan and Bogomolov, Emil and Notchenko, Alexandr and Mao, Fung and Artemov, Alexey and Zorin, Denis and Burnaev, Evgeny},
 booktitle = {Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
 pages = {1869--1877},
 title = {Making DensePose fast and light},
 year = {2021}
}
</code></pre></li></ul></div><footer><hr>© <a href=https://artonson.github.io>Alexey Artemov</a> 2021–2022 | <a href=mailto:a.artemov@skoltech.ru>Email</a> | <a href=https://github.com/artonson>Github</a> | <a href="https://scholar.google.ru/citations?user=5lVsH-IAAAAJ&hl=en">Scholar</a> | <a href=https://www.youtube.com/channel/UCO946RPg2Yp2PXFzon9_73g>YouTube</a> | <a href=https://www.linkedin.com/in/artonson/>LinkedIn</a> | <a href=https://twitter.com/artonson>Twitter</a></footer></body></html>
<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Education on Alexey Artemov</title><link>https://artonson.github.io/teaching/</link><description>Recent content in Education on Alexey Artemov</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>© Yuanyuan GE 2020</copyright><lastBuildDate>Wed, 01 Sep 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://artonson.github.io/teaching/index.xml" rel="self" type="application/rss+xml"/><item><title>Foundations of Software Engineering</title><link>https://artonson.github.io/teaching/fse/</link><pubDate>Wed, 01 Sep 2021 00:00:00 +0000</pubDate><guid>https://artonson.github.io/teaching/fse/</guid><description>Course Contents Topics include:
Unix fundamentals: shell and command line, scripting, filesystem, streams and pipes, parameter parsing, remote machine, and ssh, etc., Software engineering in teams: code review and version control, reproducibility and containers, testing and test-driven development, improving code style, software deployment, and APIs, etc., Software design: team organization, software specifications, software project management, software design methodologies, object-oriented software design, etc. As a project, the students will be required to work in teams to design, engineer, test, and deploy a real large software system using the principles described in this course.</description></item><item><title>Geometric Computer Vision</title><link>https://artonson.github.io/teaching/gcv/</link><pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate><guid>https://artonson.github.io/teaching/gcv/</guid><description>Course Contents Lecture 1. Course introduction and overview. The geometry processing pipeline. 3D representations in vision and graphics Lecture 2. Hardware systems for 3D data acquisition Lecture 3. Dense [2D] range images Lecture 4. Point set-based modalities. Invariance and equivariance in learning. Lecture 5. Learning from volumetric depth Lecture 6. Learning with implicit functions Lecture 7. Surface modalities Lecture 8. CAD/vectorized modalities</description></item><item><title>Machine Learning in High Energy Physics&lt;br/> Summer Schools (2017—2019)</title><link>https://artonson.github.io/teaching/mlhep/</link><pubDate>Thu, 01 Aug 2019 00:00:00 +0000</pubDate><guid>https://artonson.github.io/teaching/mlhep/</guid><description>There are plenty of essential problems in high energy physics that can be solved using Machine Learning methods. These vary from online data filtering and reconstruction to offline data analysis.
Students of the school will receive a theoretical and practical introduction to this new field and will be able to apply acquired knowledge to solve their own problems. Topics ranging from decision trees to deep learning and hyperparameter optimisation will be covered with concrete examples and hands-on tutorials.</description></item><item><title>Machine Learning Summer School 2019</title><link>https://artonson.github.io/teaching/mlss/</link><pubDate>Mon, 15 Jul 2019 00:00:00 +0000</pubDate><guid>https://artonson.github.io/teaching/mlss/</guid><description>Specific days where I participated were:
DAY-2 (27.08): Alexey Artemov, Justin Solomon - Geometric Techniques in ML DAY-8 (04.09): Alexey Artemov, Michael Bronstein - Graph Neural Networks</description></item><item><title>Applied Statistics in Machine Learning</title><link>https://artonson.github.io/teaching/asml/</link><pubDate>Sat, 01 Sep 2018 00:00:00 +0000</pubDate><guid>https://artonson.github.io/teaching/asml/</guid><description>Course Contents Lecture 1. Course introduction. Lecture 2. Resampling. Monte Carlo simulation. Bootstrap. Confidence intervals. Multiple comparisons correction. Bagging in machine learning. Lecture 3. Parametric estimation. Maximum likelihood method and its properties. Delta method. The case of vector parameter. Lecture 4. Distances between distributions. f-divergence distances. The distance of total variation. Kulbak-Leibler distance. Jensen-Shannon distance. χ2 distance. Wasserstein distance. Lecture 5. Hypothesis testing (Part 1). Statistical hypotheses and statistical criteria. Characteristics of the criteria.</description></item><item><title>Statistics of Random Processes</title><link>https://artonson.github.io/teaching/smsrp/</link><pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate><guid>https://artonson.github.io/teaching/smsrp/</guid><description>Course Contents Lecture 1. Stochastic processes and their characteristics. Lecture 2. Theory fundamentals of stochastic processes. Lecture 3. Wiener and Poisson type processes. Generation of realizations of random processes. Lecture 4. Markov chains. Lecture 5. Markov processes. Lecture 6. Stochastic models with discrete time. Lecture 7. Gaussian and conditional Gaussian models. Lecture 8. Hidden Markov models. Lecture 9. Multivariate Gaussian estimation. Kalman filter. Lecture 10. Key statistics and tests in decision theory.</description></item></channel></rss>